# 05 - OpenTelemetry Collector Setup on Kubernetes
The OpenTelemetry collector is a central component of the OpenTelemetry architecture that acts as an intermediary for collecting, transforming, and exporting telemetry data such as traces, metrics, and logs. It is designed to be flexible and scalable, supporting a variety of configurations and deployment scenarios. Below is a detailed description of its features and functionality.

## Architecture and Components 

The OpenTelemetry collector consists of several main components:

- **Receivers**: Receivers are responsible for collecting telemetry data from agents or other sources. They support various protocols and data formats, such as OTLP (OpenTelemetry Protocol), Jaeger, Prometheus, Zipkin, and many others.
- **Processors**: Processors perform operations on collected telemetry data before it is exported. These operations may include filtering, transformation, batching, and data enrichment.
- **Exporters**: Exporters send processed telemetry data to monitoring and observability backends such as Jaeger, Prometheus, Zipkin, Elastic, Splunk, and many others.
- **Extensions**: Extensions provide additional functionality such as authentication, authorization, and configuration management.

## Functionality

The OpenTelemetry collector offers a wide range of features that facilitate its use in production environments:

- **Language Independence**: The collector is language independent and can receive telemetry data from applications written in any language supported by OpenTelemetry.
- **Scalability**: It can be deployed in standalone mode or as part of a network of distributed collectors, supporting high-availability workloads and high scalability.
- **Configurability**: The configuration of the collector is highly flexible and can be defined using YAML files. The receiver, processor, exporter, and other extensions can be configured in detail.
- **Data Transformation**: Built-in processors allow data to be transformed in various ways, such as adding attributes, changing metric names, and aggregating data.
- **Multi-Backend Support**: Allows data to be sent to multiple backends simultaneously, facilitating integration with different monitoring systems.

## Deployment Modes

The OpenTelemetry collector can be deployed in different ways to suit various architectures and environments:

- **Standalone**: Run as an independent process, collecting and sending data directly.
- **Agent**: Deployed alongside applications on each host to collect data locally and send it to the central collector.
- **Gateway**: Runs as a central aggregation point for telemetry data collected by several agents.

## Best Practices

OpenTelemetry best practices help ensure that the implementation of monitoring and observability tools is efficient, scalable, secure, and easily maintainable.

- **Security**: Configure authentication and authorization to protect telemetry data.
- **Monitoring and Logging**: Use log exporters to monitor the operation of the collector itself.
- **Performance Optimization**: Use batching and memory limitation processors to manage resources efficiently.

### Step 1: Environment Preparation

Ensure that the Kubernetes cluster is up and running and that `kubectl` is correctly configured.

### Step 2: Create the ConfigMap for the Collector

#### 2.1 Create the Configuration File

Create a file named `otel-collector-configmap.yaml` with the following content:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: default
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:

    processors:
      batch:
      memory_limiter:
        limit_mib: 4000
        spike_limit_mib: 500
        check_interval: 5s
      resource:
        attributes:
          - key: service.name
            value: my-service

    exporters:
      logging:
        logLevel: debug
      otlp:
        endpoint: "otel-collector:4317"

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, memory_limiter, resource]
          exporters: [logging, otlp]
        metrics:
          receivers: [otlp]
          processors: [batch, memory_limiter, resource]
          exporters: [logging, otlp]
```

#### 2.2 Apply the ConfigMap

Apply the ConfigMap to the cluster:

```bash
kubectl apply -f otel-collector-configmap.yaml
```

### Step 3: Deploy the OpenTelemetry Collector

#### 3.1 Create the Deployment

Create a file named `otel-collector-deployment.yaml` with the following content:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  namespace: default
  labels:
    app: otel-collector
spec:
  replicas: 1
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: otel/opentelemetry-collector-contrib:latest
        imagePullPolicy: Always
        args: ["--config=/etc/otel-collector-config.yaml"]
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /etc
          subPath: otel-collector-config.yaml
      volumes:
      - name: otel-collector-config-vol
        configMap:
          name: otel-collector-config
          items:
            - key: otel-collector-config.yaml
              path: otel-collector-config.yaml
```

**Note:**

- **volumeMounts:** The volume is mounted at `/etc` with `subPath` specified to ensure that the configuration file is accessible as `/etc/otel-collector-config.yaml` inside the container.
- **args:** The specified path for the configuration file (`--config=/etc/otel-collector-config.yaml`) matches the path of the file inside the container.

#### 3.2 Apply the Deployment

Apply the Deployment to the cluster:

```bash
kubectl apply -f otel-collector-deployment.yaml
```

### Step 4: Expose the Collector

#### 4.1 Create the Service

Create a file named `otel-collector-service.yaml` with the following content:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  namespace: default
spec:
  ports:
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  selector:
    app: otel-collector
```

#### 4.2 Apply the Service

Apply the Service to the cluster:

```bash
kubectl apply -f otel-collector-service.yaml
```

### Step 5: Verify the Installation

#### 5.1 Check the Collector Pod Status

Verify that the pod is running:

```bash
kubectl get pods -l app=otel-collector
```

#### 5.2 Check the Collector Logs

Verify the logs to ensure there are no errors:

```bash
kubectl logs <pod-name> -c otel-collector
```

Replace `<pod-name>` with the actual name of the pod.

### Conclusion

You have successfully configured and deployed the OpenTelemetry Collector on Kubernetes, ensuring that the configuration file is correctly mounted and accessible. The Collector is now ready to receive and process telemetry data from services in the cluster.

PS."Still working" - l'OpenTelemetry Collector non riesce a trovare il file di configurazione specificato (/conf/otel-collector-config.yaml).Da risolvere  
