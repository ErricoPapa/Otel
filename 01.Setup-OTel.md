# 01 - Setup OpenTelemetry

OpenTelemetry (OTel) is an observability framework and toolkit that includes a shared language, data model, and unification of underlying propagation behaviors. OTel is designed to manage telemetry data, such as tracks, parameters, and logs, and is open source, allowing for greater flexibility.

# Components of OpenTelemetry

### 1. Specification

The OpenTelemetry specification is the foundational document that defines the architecture and standards for all components within the project. It includes:

- **Data Models**: Specifications for traces, metrics, and logs. For example, traces are defined as a series of events representing a single transaction or operation across various services, and each trace consists of spans with attributes, timing information, and status codes.
- **API and SDK Guidelines**: Rules for the design and behavior of APIs and SDKs, ensuring consistency across different implementations. This includes the contract for the API's surface area, error handling, concurrency, and thread safety considerations.
- **Protocol Definitions**: Detailed descriptions of how data should be encoded, transmitted, and processed. This includes specifications for data serialization formats (like Protobuf), network protocols (HTTP, gRPC), and telemetry data export standards.

### 2. Standard Protocol

The OpenTelemetry protocol (OTLP) defines a unified approach for transmitting telemetry data across different systems. Key aspects include:

- **Encoding and Transport**: OTLP supports both gRPC and HTTP/JSON for data transport. gRPC is preferred for efficiency and support for bidirectional streaming, while HTTP/JSON offers simplicity and compatibility with various web technologies.
- **Data Structures**: Defines structures for different telemetry data types, such as traces, metrics, and logs. For instance, a trace might be represented as a sequence of spans with specific fields for operation name, start and end times, and status.
- **Interoperability**: Ensures that data collected from various sources can be consistently processed and understood, regardless of the originating language or platform.

### 3. Semantic Conventions

Semantic conventions establish standardized naming and structuring of telemetry data, ensuring clarity and consistency. This includes:

- **Attributes**: Standardized attribute names for common data points, like HTTP request methods (`http.method`), response status codes (`http.status_code`), or database operations (`db.statement`).
- **Resource Identifiers**: Conventions for identifying the entity that generated the telemetry, such as service names, instance IDs, and version numbers.
- **Event Naming**: Guidelines for naming events within a trace, providing clear and uniform descriptions of actions, such as `db.query` or `cache.miss`.

### 4. APIs

OpenTelemetry provides language-specific APIs to allow applications to generate telemetry data. The APIs include:

- **Tracing API**: Allows developers to create and manage spans, add attributes, events, and set statuses. It includes context propagation mechanisms to correlate traces across service boundaries.
- **Metrics API**: Defines instruments like counters, gauges, and histograms for recording quantitative measurements. It supports synchronous and asynchronous instruments for different types of metric collection.
- **Logging API**: Specifies how to record log entries, capturing information like log levels, messages, and associated trace context.

### 5. Language SDKs

Language SDKs implement the OpenTelemetry APIs and provide additional functionality. They include:

- **Exporters**: Components that send collected telemetry data to various backends (e.g., Jaeger, Prometheus, Elasticsearch). Exporters are configurable, allowing for flexibility in choosing the storage and analysis systems.
- **Samplers**: Define sampling strategies to control the volume of data collected, such as always sampling, never sampling, or probabilistic sampling based on trace ID.
- **Context Propagation**: Mechanisms to propagate trace context across thread and network boundaries, ensuring that traces are accurately correlated across distributed systems.

### 6. Library Ecosystem

This ecosystem consists of auto-instrumentation libraries for popular frameworks and libraries, enabling easy integration with minimal manual effort. Examples include:

- **Web Frameworks**: Libraries for frameworks like Flask, Express, and Spring, automatically capturing HTTP request/response details.
- **Database Clients**: Instrumentation for database clients (e.g., MySQL, PostgreSQL), capturing query execution details and timing.
- **Messaging Systems**: Support for message queues and brokers, like Kafka or RabbitMQ, capturing message send/receive operations and associated metadata.

### 7. Automatic Instrumentation Components

Automatic instrumentation tools, such as agents, dynamically inject telemetry collection logic into applications. They provide:

- **Bytecode Manipulation**: For languages like Java, agents can modify bytecode at runtime to insert telemetry hooks without altering the source code.
- **Native Hooks**: For languages like Python or JavaScript, automatic instrumentation involves wrapping existing library functions to insert tracing or metrics collection.
- **Configuration Options**: Users can control the extent and behavior of automatic instrumentation via configuration files or environment variables, specifying which components to instrument and how to process the data.

### 8. OpenTelemetry Collector

The OpenTelemetry Collector is a critical piece that aggregates and processes telemetry data before exporting it.
We will talk more about this in **Lab 5**.

### 9. Additional Tools and Community Assets

- **OpenTelemetry Operator for Kubernetes**: A Kubernetes operator that automates the management of OpenTelemetry components, such as SDKs, Collector instances, and instrumentation configurations, within a Kubernetes cluster. It simplifies the deployment and scaling of observability infrastructure.
- **Helm Charts**: Pre-configured templates for deploying OpenTelemetry components on Kubernetes using Helm. They encapsulate best practices and common configurations, making it easier to set up monitoring and observability.
- **Community Assets for FaaS**: Specialized libraries and tools for integrating OpenTelemetry with Function-as-a-Service (FaaS) platforms like AWS Lambda, Google Cloud Functions, or Azure Functions. These assets ensure that telemetry data is captured accurately, even in serverless environments where the underlying infrastructure is abstracted.


## Making a System Observable

To make a system observable, it must be **instrumented**: code from the system’s components must emit **traces**, **metrics**, and **logs**.

### 1. Traces

### Definition
Traces represent the end-to-end journey of requests as they traverse through various components of a system. They provide visibility into the latency and dependencies of different operations.

### Components

- **Span:** Represents an individual operation within a trace. Each span has:
  - A unique span ID.
  - A parent span ID if it's a child of another span.
  - A trace ID to group all spans that are part of the same trace.
  - Metadata such as attributes, events, and status.

- **Trace:** A collection of spans linked together with a shared trace ID, illustrating the path of a request through a system.

## Example Trace
Imagine a web application that processes an HTTP request by querying a database and calling an external API.

- **HTTP Request Span:** The trace starts with an HTTP request span.
  - **Trace ID:** `abcd1234`
  - **Span ID:** `1234`
  - **Operation Name:** HTTP GET /user
  - **Attributes:** `{"http.method": "GET", "http.url": "/user"}`
  - **Start Time:** `2024-07-29T12:00:00Z`
  - **End Time:** `2024-07-29T12:00:01Z`

- **Database Query Span:** A child span for querying the database.
  - **Parent Span ID:** `1234`
  - **Span ID:** `5678`
  - **Operation Name:** DB Query
  - **Attributes:** `{"db.statement": "SELECT * FROM users WHERE id = ?", "db.system": "PostgreSQL"}`
  - **Start Time:** `2024-07-29T12:00:00Z`
  - **End Time:** `2024-07-29T12:00:00.5Z`

- **External API Call Span:** Another child span for an external API call.
  - **Parent Span ID:** `1234`
  - **Span ID:** `9101`
  - **Operation Name:** API Call
  - **Attributes:** `{"api.url": "https://api.example.com/data", "api.method": "POST"}`
  - **Start Time:** `2024-07-29T12:00:00.5Z`
  - **End Time:** `2024-07-29T12:00:01Z`

### Visualization
In a distributed tracing tool like Jaeger or Zipkin, the trace would be visualized as a tree where each span is a node, showing the sequence and duration of operations.

### 2. Metrics

### Definition
Metrics are numerical data points collected over time, providing insights into the performance and health of systems.

### Types of Metrics

- **Counters:** Measure cumulative values that can only increase (e.g., number of requests).
- **Gauges:** Measure values that can go up or down (e.g., current memory usage).
- **Histograms:** Measure the distribution of values (e.g., request latencies).
- **Summaries:** Provide aggregate statistics such as averages and percentiles.

### Example Metrics

- **HTTP Request Count (Counter):**
  - **Metric Name:** `http_requests_total`
  - **Labels:** `{"method": "GET", "status": "200"}`
  - **Value:** `1234`
  - **Description:** Total number of HTTP GET requests with a 200 status code.

- **Response Latency (Histogram):**
  - **Metric Name:** `http_request_duration_seconds`
  - **Labels:** `{"method": "POST"}`
  - **Buckets:** `[0.1, 0.5, 1, 2.5, 5, 10]`
  - **Description:** Distribution of HTTP POST request durations in seconds.

- **Memory Usage (Gauge):**
  - **Metric Name:** `memory_usage_bytes`
  - **Value:** `5242880` (5 MB)
  - **Description:** Current memory usage in bytes.

### Visualization
In a monitoring tool like Prometheus or Grafana, metrics are visualized through graphs, charts, and dashboards to track trends and set up alerts.

### 3. Logs

### Definition
Logs are timestamped records of events that occur in a system. They are primarily used for debugging and understanding the state of an application at specific points in time.

### Types of Logs

- **Structured Logs:** Logs formatted in a consistent structure, often in JSON, making them easier to query and analyze.
- **Unstructured Logs:** Plain text logs that may vary in format and structure.

## Example Logs

- **Structured Log:**
  ```json
  {
    "timestamp": "2024-07-29T12:00:00Z",
    "level": "INFO",
    "message": "User login successful",
    "user_id": "12345",
    "ip_address": "192.168.1.1"
  }

- **Unstructured Log:**
  2024-07-29 12:00:00 INFO User login successful user_id=12345 ip_address=192.168.1.1

# OpenTelemetry Approach

### Traces and Metrics
OpenTelemetry defines APIs for creating and managing traces and metrics. SDKs for different languages provide implementations for these APIs, allowing you to instrument your code to capture telemetry data.

### Logs
OpenTelemetry provides a "Logs Bridge API" to integrate existing logging systems with OpenTelemetry. This allows logs to be correlated with traces and metrics.

### Instrumentation Methods

Using OpenTelemetry, you can instrument your code in two primary ways:

1. **Code-based solutions** via official APIs and SDKs for most languages.
2. **Zero-code solutions**.

**Code-based** solutions allow you to get deeper insight and rich telemetry from your application itself. They let you use the OpenTelemetry API to generate telemetry from your application, complementing the telemetry generated by zero-code solutions.

The current status of the major functional components for OpenTelemetry is as follows:


| Language      | Traces     | Metrics     | Logs          |
|---------------|------------|-------------|---------------|
| C++           | Stable     | Stable      | Stable        |
| C#/.NET       | Stable     | Stable      | Stable        |
| Erlang/Elixir | Stable     | Development | Development   |
| Go            | Stable     | Stable      | Beta          |
| Java          | Stable     | Stable      | Stable        |
| JavaScript    | Stable     | Stable      | Development   |
| PHP           | Stable     | Stable      | Stable        |
| Python        | Stable     | Stable      | Development   |
| Ruby          | Stable     | Development | Development   |
| Rust          | Beta       | Alpha       | Alpha         |
| Swift         | Stable     | Development | Development   |



**Zero-code** solutions are great for getting started or when you can’t modify the application to get telemetry. They provide rich telemetry from the libraries you use and/or the environment your application runs in, offering insights about what’s happening *at the edges* of your application.

## OpenTelemetry Goals

- **Standardization**: Standardize how applications collect and send their telemetry data to back-end platforms, allowing clients and observability platforms to agree on the data format, eliminating vendor lock-in.
- **End-to-end visibility**: Provide better visibility by defining how libraries and frameworks generate telemetry data in a platform and implementation-independent manner, enhancing observability in distributed systems using different technologies.

## OpenTelemetry Components

OpenTelemetry provides both a **specification** and **implementations** in many popular programming languages.

### Specification

OpenTelemetry is first and foremost a specification. It defines the standard of what telemetry data looks like and how to build and use OpenTelemetry instrumentation.

### Implementations

OpenTelemetry API and SDK define classes, functions, and configuration mechanisms for working with telemetry data. It provides standard-compliant implementations in many popular programming languages.

### Install Helm

Helm describes the application from definition to upgrade in Helm graphs, which are used to pass resources to the Kubernetes cluster via the Kubernetes API. To install Helm, run these commands:

```sh
curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
```

### Add OpenTelemetry

Add the OpenTelemetry Helm repository:

```sh
helm repo add open-telemetry
```
